{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adatelőkészítés a pandas csomag segítségével"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az adatelőkészítés fázisa számos különféle műveletet foglal magában. Jelen workbook-ban olyan mintapéldákat tekintünk át, amelyek ezen lehetséges műveletekből igyekeznek minél többet bemutatni, de természetesen nem fedik a teljes témakört.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy változó létrehozása"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dummyfikálás bemutatásához hozzunk létre egy minta dataframe-et, majd alakítsuk át a szín változót dummy változóvá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       Nev Szemszin\n0   Aranka      kék\n1  Piroska     zöld\n2    Józsi    barna\n3  Benedek     zöld",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Nev</th>\n      <th>Szemszin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aranka</td>\n      <td>kék</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Piroska</td>\n      <td>zöld</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Józsi</td>\n      <td>barna</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Benedek</td>\n      <td>zöld</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_minta=pd.DataFrame({'Nev':['Aranka', 'Piroska', 'Józsi', 'Benedek'],\n",
    "                        'Szemszin': ['kék', 'zöld', 'barna', 'zöld']})\n",
    "df_minta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   barna  kék  zöld\n0      0    1     0\n1      0    0     1\n2      1    0     0\n3      0    0     1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>barna</th>\n      <th>kék</th>\n      <th>zöld</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a Szemszin oszlop on-hot-encoding átalakítása:\n",
    "one_hot = pd.get_dummies(df_minta['Szemszin'])\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       Nev  barna  kék  zöld\n0   Aranka      0    1     0\n1  Piroska      0    0     1\n2    Józsi      1    0     0\n3  Benedek      0    0     1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Nev</th>\n      <th>barna</th>\n      <th>kék</th>\n      <th>zöld</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aranka</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Piroska</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Józsi</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Benedek</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hozzáfűzés az eddigi dataframe-hez és a korábbi oszlop eldobása:\n",
    "df_minta = df_minta.drop('Szemszin',axis = 1)\n",
    "df_minta = df_minta.join(one_hot)\n",
    "df_minta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adatmigráció"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Első lépésként olvassuk be a *fiktiv_szemely1.csv* és a *fiktiv_szemely2.csv* fájlokat, majd migráljuk őket!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Dropbox\\\\0_DSalapjai\\\\Python_programok\\\\fiktiv_szemely1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-c2c373de9319>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m szem1 = pd.read_csv('C:\\\\Dropbox\\\\0_DSalapjai\\\\Python_programok\\\\fiktiv_szemely1.csv',\n\u001B[0m\u001B[1;32m      5\u001B[0m                     sep=';', header=0)\n\u001B[1;32m      6\u001B[0m szem2 = pd.read_csv('C:\\\\Dropbox\\\\0_DSalapjai\\\\Python_programok\\\\fiktiv_szemely2.csv',\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[1;32m    684\u001B[0m     )\n\u001B[1;32m    685\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 686\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    687\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    451\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 452\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfp_or_buf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    453\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    454\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    934\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    935\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 936\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    937\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    938\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1166\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"c\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1167\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"c\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1168\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1169\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1170\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"python\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m   1996\u001B[0m         \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"usecols\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0musecols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1997\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1998\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1999\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2000\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'C:\\\\Dropbox\\\\0_DSalapjai\\\\Python_programok\\\\fiktiv_szemely1.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "szem1 = pd.read_csv('C:\\\\Dropbox\\\\0_DSalapjai\\\\Python_programok\\\\fiktiv_szemely1.csv',\n",
    "                    sep=';', header=0)\n",
    "szem2 = pd.read_csv('C:\\\\Dropbox\\\\0_DSalapjai\\\\Python_programok\\\\fiktiv_szemely2.csv',\n",
    "                    sep=';', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kukkantsunk bele, hogy milyen adatokat tartalmaznak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Migráljuk a 2 állományt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem = pd.concat([szem1, szem2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha csak a DataFrame oszlopneveinet  szeretnénk lekérni, akkor ezt a **list** függvénnyel valósíthatjuk meg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(szem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mekkora a migrált adathalmaz mérete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A felesleges változókat pedig töröljük!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del szem1\n",
    "del szem2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adattisztítás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hibás adatok kezelése"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizsgáljuk meg közelebbről a numerikus értékeket tartalmazó oszlopok adatait!  \n",
    "A numerikus értékek legnagyobb és legkisebb értékeit az **nlargest** és **nsmallest** függvényekkel jeleníthetjük meg. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.nlargest(10, 'eletkor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.nsmallest(10, 'eletkor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nyilvánvaló adathibák esetében egyik lehetséges (és egyben legegyszerűbb) mód a hibás adatok törlése (nem túl sok hibás adat esetén ajánlott csak).   \n",
    "Töröljük azon életkor adatokat, ahol az életkor nem a [18, 120] intervallumba eseik!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.loc[szem.eletkor > 120, 'eletkor'] = np.nan\n",
    "szem.loc[szem.eletkor < 18, 'eletkor'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Csupán ellenőrzésképpen nézzük meg, hogy pl a 20-30-as idexű rekordok adatai hogyan módosultak. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem[20:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasonlóan járjunk el a *testsuly* és *testmagassag* adatok esetében is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.nlargest(10, 'testsuly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.nsmallest(10, 'testsuly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.loc[szem.testsuly > 200, 'testsuly'] = np.nan\n",
    "szem.loc[szem.testsuly < 40, 'testsuly'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.nlargest(10, 'testmagassag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.nsmallest(10, 'testmagassag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.loc[szem.testmagassag > 250, 'testmagassag'] = np.nan\n",
    "szem.loc[szem.testmagassag < 100, 'testmagassag'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiányzó adatok és duplumok kezelése"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Üres adatok lekérdezése"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az **isnull** függvény segítségével le tudjuk kérdezni, hogy a DataFrame-ben hol találunk NAN értékeket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.isnull()  #vagy: pd.isnull(szem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mivel ez így eléggé átláthatatlan, ezért célszerű továbbfűzni az előző gondolatot és lekérdezni azon sorok indexeit, amelyek tartalmaznak NAN értéket.\n",
    "Ehhez első lépésben nézzük meg, hogy hogyan lehet lekérdezni, hogy mely sorok/oszlopok tartalmazak NAN értéket. Erre sok lehetőségünk van, megvalósíthatjuk például így is:   \n",
    "</br>   \n",
    "Mely oszlopok tartalmaznak NAN adatot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.isnull().any(axis=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mely sorok tartalmaznak NAN adatot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az üres adatot tartalmazó sorok indexeit többféleképpen is kilistázhatjuk. Leggyorsabb talán a *szem.isnull().any(axis=1).nonzero()* utasítás, de hasonló eredményt érhetünk el a következőképpen is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem[szem.isnull().any(1)==True].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az előző utasítások int számokat adott vissza, ha szeretnénk könnyen kezelni őket, akkor listává érdemes konvertálni, vagy egy tömbbe tenni őket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem[szem.isnull().any(1)==True].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(szem[szem.isnull().any(1)==True].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha arra vagyunk kiváncsiak, hogy hány olyan rekordunk van, amely NaN adatot tartalmaz, akkor az előző lista, vagy tömb méretét kell lekérdezni. De hasonló eredményt kapnánk a *szem.isnull().any(1).nonzero()[0].size* utasítással is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(szem[szem.isnull().any(1)==True].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(szem[szem.isnull().any(1)==True].index).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hiányzó adatok pótlása"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manuális pótlás**: Ha valamely adatot utólagosan beszereztük, akkor könnyen tudjuk  a DataFrame-ben is pótolni.   \n",
    "Tegyük fel, hogy a *19*-es *id*-jú személy testmagasságát utólagosan megtudtuk, s ez *180cm*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.loc[szem.id == 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.loc[szem.id == 19, 'testmagassag'] = 180\n",
    "szem.loc[szem.id == 19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feltöltés globális konstanssal**: ebben a műveletben a **replace** függvény lesz segítségünkre, a hiányzó értékekre pedig az **np.nan** függvénnyel hivatkozhatunk.  \n",
    "Cseréljül le a hiányzó *eletkor* adatokat *ismeretlen* értékekre.   \n",
    "Először vizsgáljuk meg, hogy hol tartalmaz NaN adatokat az *eletkor* mező."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem[szem['eletkor'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.iloc[151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.eletkor.replace(np.nan, 'ismeretlen', inplace=True)\n",
    "szem.iloc[151]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mivel a NAN értékeket sokkal könnyebben tudjuk kezelni, ezért írjuk vissza az *eletkor* oszlopba a *NAN* adatokat az *'ismeretlen'* adatok helyett."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.eletkor.replace('ismeretlen', np.nan, inplace=True)\n",
    "szem.iloc[151]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hiányzó értékeket tartalmazó rekordok törlése"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hiányzó adatok törlése a **dropna** metódussal valósítható meg. Segítségével törölhetünk:  \n",
    "- sorokat (*axis=0*),\n",
    "- oszlopokat (*axis=1*) \n",
    "\n",
    "valamit olyan sorokat/oszlopokat, amelyekben:\n",
    "- legalább 1 NAN adat van (*how='any'*)\n",
    "- minden adat NAN (*how='all'*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.dropna(axis=0, how='all', inplace=True)\n",
    "szem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.dropna(axis=0, how='any', inplace=True)\n",
    "szem.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adattranszformáció"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hozzunk létre egy új oszlopot *bmi* néven, amely az egyes személykre kiszámított testtömeg indexet tartalmazza. A testömeg index a kilogrammban mért testtömeg és a méterben mért tesmagasság négyzetének hányadosa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Származtatott oszlop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem['bmi'] = szem['testsuly']/((szem['testmagassag']/100)**2)\n",
    "szem.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adatdiszkretizáció"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az adatok diszretizálásának egyik lehetséges módja a **vödrözési technika** alkalmazása.  \n",
    "Egyenlőszélességi vödröket a **cut** metódussal, egyenlő mélységű vödröket pedig a **qcut** metódussal  tudunk  kialakítani.\n",
    "<br>  \n",
    "Hozzunk létre *korcsopnev* néven új attribútumot, ahova a személyeket diszkretizáljuk életkoruk alapján *fiatal*, *középkorú* és *idős*  kategóriákba **egyenlő szélességű vödrök** alkalmazásával!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem['korcsopnev'] = pd.cut(szem.eletkor, 3)\n",
    "szem.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem['korcsopnev'] = pd.cut(szem.eletkor, 3, \n",
    "                            labels=['fiatal', 'kozepkoru', 'idos'])\n",
    "szem.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tegyük ugyanezt meg **egyenlő mélységű vödrök** alkalmazásával, s az eredmény tároljuk el a *korcsopnev2* oszlopban.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem['korcsopnev2'] = pd.qcut(szem.eletkor, 3, \n",
    "                              labels=['fiatal', 'kozepkoru', 'idos'])\n",
    "szem.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mivel a későbbiekben a *korcsopnev2* oszlopra nincs szükségünk, azért töröljük:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.drop('korcsopnev2', axis=1, inplace=True)\n",
    "szem.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizáció"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Min-max normalizáció**: Normáljuk a *szem* adathalmaz numerikus értékeit a [0, 1] intervallumba a min-max normalizációs módszer alapján! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['testsuly', 'testmagassag', 'eletkor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    col_minmax = col + '_minmaxnorm'\n",
    "    szem[col_minmax] = (szem[col] - min(szem[col]))/(max(szem[col])-min(szem[col]))\n",
    "szem.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasonló eredményt értünk volna el a következő utasítás alkalmazásával is:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *szem[col_minmax] = (szem[col] - szem[col].min())/(szem[col].max()-szem[col].min())*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "**Zéruspont normalizáció**: Normalizáljuk szintén a numerikus adatokat zéruspont normalizációval!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    col_zscore = col + '_zscore'\n",
    "    szem[col_zscore] = (szem[col] - np.mean(szem[col]))/np.std(szem[col])\n",
    "szem.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tételezzük fel, hogy a továbbiakban nincs szükségünk a z-score normált értékekre, azért töröljük ezen oszlopokat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.drop(['testsuly_zscore', 'testmagassag_zscore', 'eletkor_zscore'], \n",
    "          axis=1, inplace=True)\n",
    "szem.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplikált sorok törlése"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A duplikált sorokat a ** drop_duplicates** metódussal törölhetjük:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.drop_duplicates(inplace=True)\n",
    "szem.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mintavételezés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visszatevés nélküli mintát** a **sample** metódussal tudunk kiválasztani. Lehetőségünk van egy meghatározott elemszámú mintát, illetve a teljes adathalmaz valahány százalékát is kiválasztani. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.sample(frac=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visszatevéses mintavételezés**: az **iloc** és az **np.random.choice** függvények segítségével valósítható meg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.iloc[np.random.choice(szem.index, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tisztított adatok mentése"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha már ennyit dolgoztunk vele, akkor a tisztított migrált adathalmazt írjuk ki egy csv fájlba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "szem.to_csv('C:\\\\Dropbox\\\\0_DSalapjai\\\\Python_programok\\\\fiktiv_szemely_migralt.csv',\n",
    "            sep=';', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}